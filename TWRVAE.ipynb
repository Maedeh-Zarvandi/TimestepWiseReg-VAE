{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADL-TWRVAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFKs7FRlqQiD",
        "outputId": "5b9107b8-b40b-4231-be36-7bee08b2f279"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYhFORS4quyM",
        "outputId": "66af67cb-6db9-4a1f-b0ba-4a877f389b6a"
      },
      "source": [
        "%cd /content/drive/MyDrive/TWR-VAE/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/TWR-VAE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukZlqTpIWnJi",
        "outputId": "1b6c172a-7ec4-4a69-805f-c816ad44752c"
      },
      "source": [
        "!python lang_model/main.py -dt wiki --z_type normal --batch_size 32 --gpu_id 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=32, dataset='wiki', dropout=0.5, embedding_size=512, epochs=1000, gpu_id='0', hidden_size=256, layers=1, load=False, lr=0.0001, min_word_count=1, model_dir='', no_cuda=False, partial=False, partial_type='last75', rnn_type='lstm', save=True, setting='standard', z_type='normal', zdim=32)\n",
            "base_path= ./lang_model\n",
            "start to load Corpus data\n",
            "start to build dictionary\n",
            "start to make one-hot vectors\n",
            "start to load Corpus data\n",
            "start to build dictionary\n",
            "start to make one-hot vectors\n",
            "start to load Corpus data\n",
            "start to build dictionary\n",
            "start to make one-hot vectors\n",
            "voca_dim=28854\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Encoder(\n",
            "  (embedding): Embedding(28854, 512, padding_idx=0)\n",
            "  (rnn): LSTM(512, 256, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (linear_mu): Linear(in_features=256, out_features=32, bias=True)\n",
            "  (linear_var): Linear(in_features=256, out_features=32, bias=True)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(28854, 512, padding_idx=0)\n",
            "  (rnn): LSTM(544, 256, dropout=0.5)\n",
            "  (z2h_c): Linear(in_features=32, out_features=256, bias=False)\n",
            "  (out): Linear(in_features=256, out_features=28854, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 0: recon_loss=374.9714, kl_loss=0.1255, nll_loss=375.0969, nll_loss_perword=6.4095, ppl=607.5670, acc=0.1380\n",
            "Eval: recon_loss:360.5996, kl_loss:4.0153, nll_loss:364.6149, nll_loss_perword=6.1216, ppl:455.6083, mi:0.5583\n",
            "Eval: recon_loss:348.0341, kl_loss:4.0203, nll_loss:352.0544, nll_loss_perword=6.0723, ppl:433.6692, mi:0.5920\n",
            "--------------------------\n",
            "Time: 1m 8s| Train 1: recon_loss=352.8603, kl_loss=0.2614, nll_loss=353.1217, nll_loss_perword=6.0340, ppl=417.3655, acc=0.1657\n",
            "--------------------------\n",
            "Time: 1m 9s| Train 2: recon_loss=342.6170, kl_loss=0.2761, nll_loss=342.8931, nll_loss_perword=5.8592, ppl=350.4370, acc=0.1774\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 3: recon_loss=335.2384, kl_loss=0.3160, nll_loss=335.5544, nll_loss_perword=5.7338, ppl=309.1358, acc=0.1839\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 4: recon_loss=328.9959, kl_loss=0.3484, nll_loss=329.3443, nll_loss_perword=5.6277, ppl=278.0125, acc=0.1898\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 5: recon_loss=323.8867, kl_loss=0.3763, nll_loss=324.2629, nll_loss_perword=5.5408, ppl=254.8916, acc=0.1939\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 6: recon_loss=319.2847, kl_loss=0.3953, nll_loss=319.6799, nll_loss_perword=5.4625, ppl=235.6922, acc=0.1978\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 7: recon_loss=315.3147, kl_loss=0.4074, nll_loss=315.7221, nll_loss_perword=5.3949, ppl=220.2794, acc=0.2012\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 8: recon_loss=311.7006, kl_loss=0.4217, nll_loss=312.1223, nll_loss_perword=5.3334, ppl=207.1380, acc=0.2043\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 9: recon_loss=308.3965, kl_loss=0.4376, nll_loss=308.8341, nll_loss_perword=5.2772, ppl=195.8204, acc=0.2073\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 10: recon_loss=305.4033, kl_loss=0.4500, nll_loss=305.8533, nll_loss_perword=5.2263, ppl=186.0963, acc=0.2100\n",
            "Eval: recon_loss:312.4943, kl_loss:1.3653, nll_loss:313.8597, nll_loss_perword=5.2695, ppl:194.3165, mi:1.6671\n",
            "Eval: recon_loss:299.1289, kl_loss:1.2971, nll_loss:300.4260, nll_loss_perword=5.1818, ppl:178.0007, mi:1.6491\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 11: recon_loss=302.6281, kl_loss=0.4705, nll_loss=303.0987, nll_loss_perword=5.1792, ppl=177.5397, acc=0.2126\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 12: recon_loss=300.0463, kl_loss=0.4878, nll_loss=300.5341, nll_loss_perword=5.1354, ppl=169.9275, acc=0.2152\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 13: recon_loss=297.5614, kl_loss=0.5005, nll_loss=298.0620, nll_loss_perword=5.0931, ppl=162.8988, acc=0.2175\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 14: recon_loss=295.3058, kl_loss=0.5104, nll_loss=295.8163, nll_loss_perword=5.0548, ppl=156.7663, acc=0.2195\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 15: recon_loss=293.0980, kl_loss=0.5248, nll_loss=293.6229, nll_loss_perword=5.0173, ppl=150.9995, acc=0.2219\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 16: recon_loss=290.9999, kl_loss=0.5397, nll_loss=291.5396, nll_loss_perword=4.9817, ppl=145.7188, acc=0.2240\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 17: recon_loss=289.0044, kl_loss=0.5576, nll_loss=289.5621, nll_loss_perword=4.9479, ppl=140.8771, acc=0.2260\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 18: recon_loss=287.0875, kl_loss=0.5742, nll_loss=287.6618, nll_loss_perword=4.9154, ppl=136.3761, acc=0.2280\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 19: recon_loss=285.2721, kl_loss=0.5913, nll_loss=285.8634, nll_loss_perword=4.8847, ppl=132.2491, acc=0.2301\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 20: recon_loss=283.4791, kl_loss=0.6020, nll_loss=284.0812, nll_loss_perword=4.8542, ppl=128.2822, acc=0.2320\n",
            "Eval: recon_loss:299.3639, kl_loss:1.4099, nll_loss:300.7738, nll_loss_perword=5.0498, ppl:155.9889, mi:1.7727\n",
            "Eval: recon_loss:286.7648, kl_loss:1.3824, nll_loss:288.1472, nll_loss_perword=4.9700, ppl:144.0272, mi:1.8296\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 21: recon_loss=281.7468, kl_loss=0.6179, nll_loss=282.3648, nll_loss_perword=4.8249, ppl=124.5746, acc=0.2340\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 22: recon_loss=280.0870, kl_loss=0.6268, nll_loss=280.7138, nll_loss_perword=4.7967, ppl=121.1094, acc=0.2357\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 23: recon_loss=278.4646, kl_loss=0.6410, nll_loss=279.1056, nll_loss_perword=4.7692, ppl=117.8264, acc=0.2373\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 24: recon_loss=276.8952, kl_loss=0.6573, nll_loss=277.5524, nll_loss_perword=4.7427, ppl=114.7405, acc=0.2390\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 25: recon_loss=275.3933, kl_loss=0.6661, nll_loss=276.0594, nll_loss_perword=4.7172, ppl=111.8502, acc=0.2407\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 26: recon_loss=273.9150, kl_loss=0.6761, nll_loss=274.5912, nll_loss_perword=4.6921, ppl=109.0790, acc=0.2424\n",
            "--------------------------\n",
            "Time: 1m 10s| Train 27: recon_loss=272.5028, kl_loss=0.6856, nll_loss=273.1884, nll_loss_perword=4.6681, ppl=106.4955, acc=0.2437\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 28: recon_loss=271.1334, kl_loss=0.6983, nll_loss=271.8316, nll_loss_perword=4.6449, ppl=104.0550, acc=0.2450\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 29: recon_loss=269.7953, kl_loss=0.7123, nll_loss=270.5076, nll_loss_perword=4.6223, ppl=101.7271, acc=0.2464\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 30: recon_loss=268.5788, kl_loss=0.7242, nll_loss=269.3030, nll_loss_perword=4.6017, ppl=99.6548, acc=0.2472\n",
            "Eval: recon_loss:291.7009, kl_loss:1.6268, nll_loss:293.3277, nll_loss_perword=4.9248, ppl:137.6576, mi:2.1013\n",
            "Eval: recon_loss:279.6421, kl_loss:1.6124, nll_loss:281.2546, nll_loss_perword=4.8511, ppl:127.8831, mi:1.9738\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 31: recon_loss=267.2424, kl_loss=0.7290, nll_loss=267.9714, nll_loss_perword=4.5790, ppl=97.4128, acc=0.2490\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 32: recon_loss=265.9902, kl_loss=0.7380, nll_loss=266.7282, nll_loss_perword=4.5577, ppl=95.3652, acc=0.2502\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 33: recon_loss=264.8056, kl_loss=0.7475, nll_loss=265.5531, nll_loss_perword=4.5376, ppl=93.4695, acc=0.2514\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 34: recon_loss=263.6243, kl_loss=0.7594, nll_loss=264.3837, nll_loss_perword=4.5177, ppl=91.6203, acc=0.2522\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 35: recon_loss=262.5260, kl_loss=0.7689, nll_loss=263.2950, nll_loss_perword=4.4990, ppl=89.9316, acc=0.2536\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 36: recon_loss=261.3442, kl_loss=0.7784, nll_loss=262.1225, nll_loss_perword=4.4790, ppl=88.1478, acc=0.2547\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 37: recon_loss=260.2901, kl_loss=0.7848, nll_loss=261.0749, nll_loss_perword=4.4611, ppl=86.5839, acc=0.2558\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 38: recon_loss=259.2290, kl_loss=0.7964, nll_loss=260.0254, nll_loss_perword=4.4432, ppl=85.0450, acc=0.2567\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 39: recon_loss=258.2542, kl_loss=0.7966, nll_loss=259.0508, nll_loss_perword=4.4265, ppl=83.6404, acc=0.2577\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 40: recon_loss=257.1504, kl_loss=0.8105, nll_loss=257.9609, nll_loss_perword=4.4079, ppl=82.0972, acc=0.2590\n",
            "Eval: recon_loss:287.9954, kl_loss:1.7731, nll_loss:289.7685, nll_loss_perword=4.8650, ppl:129.6727, mi:1.9913\n",
            "Eval: recon_loss:276.2803, kl_loss:1.7680, nll_loss:278.0483, nll_loss_perword=4.7958, ppl:121.0029, mi:2.0383\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 41: recon_loss=256.1459, kl_loss=0.8200, nll_loss=256.9659, nll_loss_perword=4.3909, ppl=80.7132, acc=0.2602\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 42: recon_loss=255.1222, kl_loss=0.8241, nll_loss=255.9463, nll_loss_perword=4.3735, ppl=79.3190, acc=0.2612\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 43: recon_loss=254.1670, kl_loss=0.8309, nll_loss=254.9979, nll_loss_perword=4.3573, ppl=78.0440, acc=0.2621\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 44: recon_loss=253.2374, kl_loss=0.8367, nll_loss=254.0741, nll_loss_perword=4.3415, ppl=76.8218, acc=0.2630\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 45: recon_loss=252.2896, kl_loss=0.8469, nll_loss=253.1364, nll_loss_perword=4.3255, ppl=75.6007, acc=0.2640\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 46: recon_loss=251.3155, kl_loss=0.8521, nll_loss=252.1676, nll_loss_perword=4.3089, ppl=74.3594, acc=0.2652\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 47: recon_loss=250.4485, kl_loss=0.8597, nll_loss=251.3081, nll_loss_perword=4.2942, ppl=73.2754, acc=0.2662\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 48: recon_loss=249.5560, kl_loss=0.8672, nll_loss=250.4232, nll_loss_perword=4.2791, ppl=72.1756, acc=0.2669\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 49: recon_loss=248.6703, kl_loss=0.8698, nll_loss=249.5401, nll_loss_perword=4.2640, ppl=71.0947, acc=0.2679\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 50: recon_loss=247.8321, kl_loss=0.8816, nll_loss=248.7138, nll_loss_perword=4.2499, ppl=70.0979, acc=0.2687\n",
            "Eval: recon_loss:283.9939, kl_loss:1.8817, nll_loss:285.8756, nll_loss_perword=4.7997, ppl:121.4684, mi:2.1105\n",
            "Eval: recon_loss:272.5835, kl_loss:1.8774, nll_loss:274.4609, nll_loss_perword=4.7339, ppl:113.7426, mi:2.1698\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 51: recon_loss=246.9298, kl_loss=0.8869, nll_loss=247.8167, nll_loss_perword=4.2346, ppl=69.0316, acc=0.2699\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 52: recon_loss=246.1351, kl_loss=0.8918, nll_loss=247.0269, nll_loss_perword=4.2211, ppl=68.1063, acc=0.2705\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 53: recon_loss=245.2351, kl_loss=0.8964, nll_loss=246.1315, nll_loss_perword=4.2058, ppl=67.0721, acc=0.2716\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 54: recon_loss=244.5134, kl_loss=0.9067, nll_loss=245.4201, nll_loss_perword=4.1936, ppl=66.2618, acc=0.2725\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 55: recon_loss=243.7500, kl_loss=0.9086, nll_loss=244.6586, nll_loss_perword=4.1806, ppl=65.4052, acc=0.2731\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 56: recon_loss=242.9440, kl_loss=0.9185, nll_loss=243.8625, nll_loss_perword=4.1670, ppl=64.5214, acc=0.2743\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 57: recon_loss=242.1483, kl_loss=0.9181, nll_loss=243.0664, nll_loss_perword=4.1534, ppl=63.6496, acc=0.2750\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 58: recon_loss=241.4165, kl_loss=0.9257, nll_loss=242.3422, nll_loss_perword=4.1410, ppl=62.8669, acc=0.2757\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 59: recon_loss=240.6255, kl_loss=0.9336, nll_loss=241.5591, nll_loss_perword=4.1276, ppl=62.0312, acc=0.2767\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 60: recon_loss=239.9468, kl_loss=0.9364, nll_loss=240.8831, nll_loss_perword=4.1161, ppl=61.3189, acc=0.2775\n",
            "Eval: recon_loss:282.2768, kl_loss:1.9598, nll_loss:284.2366, nll_loss_perword=4.7721, ppl:118.1716, mi:2.0400\n",
            "Eval: recon_loss:270.9347, kl_loss:1.9587, nll_loss:272.8934, nll_loss_perword=4.7069, ppl:110.7087, mi:2.0771\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 61: recon_loss=239.1952, kl_loss=0.9400, nll_loss=240.1352, nll_loss_perword=4.1033, ppl=60.5401, acc=0.2783\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 62: recon_loss=238.4690, kl_loss=0.9447, nll_loss=239.4137, nll_loss_perword=4.0910, ppl=59.7983, acc=0.2794\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 63: recon_loss=237.8301, kl_loss=0.9559, nll_loss=238.7860, nll_loss_perword=4.0803, ppl=59.1604, acc=0.2799\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 64: recon_loss=237.1631, kl_loss=0.9560, nll_loss=238.1191, nll_loss_perword=4.0689, ppl=58.4901, acc=0.2807\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 65: recon_loss=236.4322, kl_loss=0.9625, nll_loss=237.3947, nll_loss_perword=4.0565, ppl=57.7705, acc=0.2815\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 66: recon_loss=235.8134, kl_loss=0.9659, nll_loss=236.7793, nll_loss_perword=4.0460, ppl=57.1662, acc=0.2825\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 67: recon_loss=235.1080, kl_loss=0.9707, nll_loss=236.0787, nll_loss_perword=4.0340, ppl=56.4859, acc=0.2831\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 68: recon_loss=234.5183, kl_loss=0.9791, nll_loss=235.4974, nll_loss_perword=4.0241, ppl=55.9277, acc=0.2838\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 69: recon_loss=233.8495, kl_loss=0.9811, nll_loss=234.8305, nll_loss_perword=4.0127, ppl=55.2939, acc=0.2848\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 70: recon_loss=233.1571, kl_loss=0.9819, nll_loss=234.1391, nll_loss_perword=4.0008, ppl=54.6445, acc=0.2856\n",
            "Eval: recon_loss:281.5221, kl_loss:2.0211, nll_loss:283.5432, nll_loss_perword=4.7605, ppl:116.8038, mi:2.1784\n",
            "Eval: recon_loss:270.1550, kl_loss:2.0155, nll_loss:272.1705, nll_loss_perword=4.6944, ppl:109.3368, mi:2.2182\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 71: recon_loss=232.5540, kl_loss=0.9857, nll_loss=233.5397, nll_loss_perword=3.9906, ppl=54.0877, acc=0.2863\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 72: recon_loss=231.9592, kl_loss=0.9892, nll_loss=232.9484, nll_loss_perword=3.9805, ppl=53.5440, acc=0.2870\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 73: recon_loss=231.3513, kl_loss=0.9985, nll_loss=232.3499, nll_loss_perword=3.9703, ppl=52.9991, acc=0.2880\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 74: recon_loss=230.7085, kl_loss=1.0026, nll_loss=231.7111, nll_loss_perword=3.9594, ppl=52.4238, acc=0.2885\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 75: recon_loss=230.1365, kl_loss=1.0025, nll_loss=231.1389, nll_loss_perword=3.9496, ppl=51.9137, acc=0.2893\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 76: recon_loss=229.6043, kl_loss=1.0136, nll_loss=230.6178, nll_loss_perword=3.9407, ppl=51.4535, acc=0.2901\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 77: recon_loss=228.9578, kl_loss=1.0155, nll_loss=229.9734, nll_loss_perword=3.9297, ppl=50.8900, acc=0.2908\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 78: recon_loss=228.4206, kl_loss=1.0177, nll_loss=229.4383, nll_loss_perword=3.9205, ppl=50.4268, acc=0.2914\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 79: recon_loss=227.8499, kl_loss=1.0197, nll_loss=228.8695, nll_loss_perword=3.9108, ppl=49.9391, acc=0.2922\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 80: recon_loss=227.2124, kl_loss=1.0242, nll_loss=228.2366, nll_loss_perword=3.9000, ppl=49.4020, acc=0.2931\n",
            "Eval: recon_loss:279.9723, kl_loss:2.0847, nll_loss:282.0570, nll_loss_perword=4.7355, ppl:113.9253, mi:2.1948\n",
            "Eval: recon_loss:268.8064, kl_loss:2.0733, nll_loss:270.8798, nll_loss_perword=4.6722, ppl:106.9296, mi:2.2411\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 81: recon_loss=226.6930, kl_loss=1.0305, nll_loss=227.7235, nll_loss_perword=3.8912, ppl=48.9707, acc=0.2939\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 82: recon_loss=226.3508, kl_loss=1.0332, nll_loss=227.3840, nll_loss_perword=3.8854, ppl=48.6874, acc=0.2941\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 83: recon_loss=225.7100, kl_loss=1.0434, nll_loss=226.7534, nll_loss_perword=3.8746, ppl=48.1656, acc=0.2951\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 84: recon_loss=225.1034, kl_loss=1.0415, nll_loss=226.1449, nll_loss_perword=3.8642, ppl=47.6674, acc=0.2961\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 85: recon_loss=224.6128, kl_loss=1.0464, nll_loss=225.6592, nll_loss_perword=3.8559, ppl=47.2734, acc=0.2965\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 86: recon_loss=224.1346, kl_loss=1.0536, nll_loss=225.1882, nll_loss_perword=3.8479, ppl=46.8945, acc=0.2973\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 87: recon_loss=223.6070, kl_loss=1.0553, nll_loss=224.6623, nll_loss_perword=3.8389, ppl=46.4750, acc=0.2980\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 88: recon_loss=223.0243, kl_loss=1.0562, nll_loss=224.0804, nll_loss_perword=3.8290, ppl=46.0152, acc=0.2987\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 89: recon_loss=222.5491, kl_loss=1.0542, nll_loss=223.6033, nll_loss_perword=3.8208, ppl=45.6416, acc=0.2996\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 90: recon_loss=222.0851, kl_loss=1.0620, nll_loss=223.1471, nll_loss_perword=3.8130, ppl=45.2872, acc=0.3002\n",
            "Eval: recon_loss:278.5733, kl_loss:2.1390, nll_loss:280.7123, nll_loss_perword=4.7130, ppl:111.3821, mi:2.1073\n",
            "Eval: recon_loss:267.6329, kl_loss:2.1261, nll_loss:269.7591, nll_loss_perword=4.6528, ppl:104.8825, mi:2.1946\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 91: recon_loss=221.6245, kl_loss=1.0661, nll_loss=222.6906, nll_loss_perword=3.8052, ppl=44.9352, acc=0.3010\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 92: recon_loss=221.0706, kl_loss=1.0697, nll_loss=222.1403, nll_loss_perword=3.7958, ppl=44.5147, acc=0.3014\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 93: recon_loss=220.5730, kl_loss=1.0696, nll_loss=221.6426, nll_loss_perword=3.7873, ppl=44.1377, acc=0.3025\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 94: recon_loss=220.1208, kl_loss=1.0742, nll_loss=221.1949, nll_loss_perword=3.7797, ppl=43.8014, acc=0.3031\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 95: recon_loss=219.6506, kl_loss=1.0725, nll_loss=220.7231, nll_loss_perword=3.7716, ppl=43.4497, acc=0.3039\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 96: recon_loss=219.1626, kl_loss=1.0774, nll_loss=220.2400, nll_loss_perword=3.7633, ppl=43.0925, acc=0.3046\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 97: recon_loss=218.7039, kl_loss=1.0818, nll_loss=219.7857, nll_loss_perword=3.7556, ppl=42.7592, acc=0.3052\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 98: recon_loss=218.2695, kl_loss=1.0850, nll_loss=219.3545, nll_loss_perword=3.7482, ppl=42.4453, acc=0.3058\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 99: recon_loss=217.8267, kl_loss=1.0864, nll_loss=218.9131, nll_loss_perword=3.7407, ppl=42.1264, acc=0.3066\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 100: recon_loss=217.3698, kl_loss=1.0909, nll_loss=218.4607, nll_loss_perword=3.7329, ppl=41.8020, acc=0.3074\n",
            "Eval: recon_loss:277.6600, kl_loss:2.1448, nll_loss:279.8048, nll_loss_perword=4.6977, ppl:109.6978, mi:2.2264\n",
            "Eval: recon_loss:266.9062, kl_loss:2.1306, nll_loss:269.0368, nll_loss_perword=4.6404, ppl:103.5841, mi:2.2156\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 101: recon_loss=216.8913, kl_loss=1.0943, nll_loss=217.9856, nll_loss_perword=3.7248, ppl=41.4640, acc=0.3079\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 102: recon_loss=216.4331, kl_loss=1.0954, nll_loss=217.5285, nll_loss_perword=3.7170, ppl=41.1414, acc=0.3087\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 103: recon_loss=216.0054, kl_loss=1.0942, nll_loss=217.0996, nll_loss_perword=3.7097, ppl=40.8410, acc=0.3095\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 104: recon_loss=215.5793, kl_loss=1.1012, nll_loss=216.6804, nll_loss_perword=3.7025, ppl=40.5495, acc=0.3103\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 105: recon_loss=215.1956, kl_loss=1.1024, nll_loss=216.2980, nll_loss_perword=3.6960, ppl=40.2854, acc=0.3107\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 106: recon_loss=214.7264, kl_loss=1.1064, nll_loss=215.8328, nll_loss_perword=3.6880, ppl=39.9664, acc=0.3114\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 107: recon_loss=214.3147, kl_loss=1.1110, nll_loss=215.4257, nll_loss_perword=3.6811, ppl=39.6894, acc=0.3120\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 108: recon_loss=213.9120, kl_loss=1.1143, nll_loss=215.0263, nll_loss_perword=3.6743, ppl=39.4194, acc=0.3128\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 109: recon_loss=213.4978, kl_loss=1.1137, nll_loss=214.6115, nll_loss_perword=3.6672, ppl=39.1410, acc=0.3137\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 110: recon_loss=213.0863, kl_loss=1.1151, nll_loss=214.2013, nll_loss_perword=3.6602, ppl=38.8676, acc=0.3144\n",
            "Eval: recon_loss:278.6017, kl_loss:2.2215, nll_loss:280.8231, nll_loss_perword=4.7148, ppl:111.5895, mi:2.1734\n",
            "Eval: recon_loss:267.8604, kl_loss:2.2074, nll_loss:270.0678, nll_loss_perword=4.6582, ppl:105.4426, mi:2.1889\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 111: recon_loss=212.6685, kl_loss=1.1177, nll_loss=213.7862, nll_loss_perword=3.6531, ppl=38.5929, acc=0.3150\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 112: recon_loss=212.2911, kl_loss=1.1208, nll_loss=213.4118, nll_loss_perword=3.6467, ppl=38.3468, acc=0.3157\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 113: recon_loss=211.8878, kl_loss=1.1208, nll_loss=213.0086, nll_loss_perword=3.6398, ppl=38.0835, acc=0.3162\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 114: recon_loss=211.5107, kl_loss=1.1284, nll_loss=212.6391, nll_loss_perword=3.6335, ppl=37.8438, acc=0.3169\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 115: recon_loss=211.1156, kl_loss=1.1295, nll_loss=212.2451, nll_loss_perword=3.6267, ppl=37.5899, acc=0.3175\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 116: recon_loss=210.7044, kl_loss=1.1324, nll_loss=211.8368, nll_loss_perword=3.6198, ppl=37.3286, acc=0.3183\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 117: recon_loss=210.3534, kl_loss=1.1368, nll_loss=211.4902, nll_loss_perword=3.6138, ppl=37.1081, acc=0.3190\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 118: recon_loss=210.0081, kl_loss=1.1382, nll_loss=211.1463, nll_loss_perword=3.6080, ppl=36.8907, acc=0.3195\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 119: recon_loss=209.5899, kl_loss=1.1388, nll_loss=210.7287, nll_loss_perword=3.6008, ppl=36.6284, acc=0.3203\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 120: recon_loss=209.2441, kl_loss=1.1390, nll_loss=210.3832, nll_loss_perword=3.5949, ppl=36.4128, acc=0.3207\n",
            "Eval: recon_loss:278.8204, kl_loss:2.2433, nll_loss:281.0637, nll_loss_perword=4.7189, ppl:112.0412, mi:2.2264\n",
            "Eval: recon_loss:268.0817, kl_loss:2.2232, nll_loss:270.3049, nll_loss_perword=4.6623, ppl:105.8746, mi:2.1749\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 121: recon_loss=208.8999, kl_loss=1.1485, nll_loss=210.0484, nll_loss_perword=3.5892, ppl=36.2051, acc=0.3215\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 122: recon_loss=208.4667, kl_loss=1.1454, nll_loss=209.6121, nll_loss_perword=3.5817, ppl=35.9362, acc=0.3223\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 123: recon_loss=208.1279, kl_loss=1.1504, nll_loss=209.2783, nll_loss_perword=3.5760, ppl=35.7318, acc=0.3230\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 124: recon_loss=207.7581, kl_loss=1.1510, nll_loss=208.9091, nll_loss_perword=3.5697, ppl=35.5071, acc=0.3236\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 125: recon_loss=207.4270, kl_loss=1.1556, nll_loss=208.5826, nll_loss_perword=3.5642, ppl=35.3095, acc=0.3240\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 126: recon_loss=207.0873, kl_loss=1.1605, nll_loss=208.2478, nll_loss_perword=3.5584, ppl=35.1081, acc=0.3246\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 127: recon_loss=206.7522, kl_loss=1.1591, nll_loss=207.9112, nll_loss_perword=3.5527, ppl=34.9068, acc=0.3253\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 128: recon_loss=206.3931, kl_loss=1.1620, nll_loss=207.5552, nll_loss_perword=3.5466, ppl=34.6950, acc=0.3257\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 129: recon_loss=206.0611, kl_loss=1.1677, nll_loss=207.2288, nll_loss_perword=3.5410, ppl=34.5021, acc=0.3265\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 130: recon_loss=205.7547, kl_loss=1.1679, nll_loss=206.9227, nll_loss_perword=3.5358, ppl=34.3221, acc=0.3271\n",
            "Eval: recon_loss:279.1463, kl_loss:2.2959, nll_loss:281.4422, nll_loss_perword=4.7252, ppl:112.7554, mi:2.1749\n",
            "Eval: recon_loss:268.3204, kl_loss:2.2772, nll_loss:270.5977, nll_loss_perword=4.6673, ppl:106.4106, mi:2.1249\n",
            "--------------------------\n",
            "Time: 1m 11s| Train 131: recon_loss=205.3992, kl_loss=1.1711, nll_loss=206.5703, nll_loss_perword=3.5298, ppl=34.1160, acc=0.3277\n",
            "--------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"lang_model/main.py\", line 298, in <module>\n",
            "    recon_loss, var_loss, acc, nll_loss, ppl = train(dataloader_train, ep)\n",
            "  File \"lang_model/main.py\", line 193, in train\n",
            "    recon_loss_total = recon_loss_total + recon_loss.item()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFhqPaIs_sU"
      },
      "source": [
        "!python main.py -dt wiki -l --model_dir lang_model/wiki_model_save/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}